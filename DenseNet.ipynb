{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xteRhXX4ZX8kECEyJ4YPo1SOeVq3kl6d","timestamp":1714080594147}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"E-AV6P4P5WXM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSYwAs51XSI3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib as plt\n","import seaborn as sns\n","import os\n","from datetime import datetime\n","import pytz\n","from pathlib import Path\n","import sklearn as sk\n","import tensorflow as tf\n","import torch\n","import torch.nn as nn\n","from torchvision.io import read_image\n","import time\n","import timeit\n","import random\n","import torchvision.models as models\n","from torchvision.datasets import CIFAR100\n","from torch.utils.data import DataLoader, Subset\n","import torchvision.transforms as transforms\n","import sklearn.metrics\n","import csv\n","import timeit\n","\n","%matplotlib inline"]},{"cell_type":"markdown","source":[],"metadata":{"id":"CN5wmJ1HtmjU"}},{"cell_type":"code","source":["# mount google drive to use as data repo\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ACGjKEG9XfZ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714160661538,"user_tz":240,"elapsed":19622,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"outputId":"d266ee09-b116-4a4a-9ad9-354ea81636da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["ls 'drive/MyDrive/DS5220: Final Project/logs/densenet'"],"metadata":{"id":"6fa2pXoVX37n","executionInfo":{"status":"ok","timestamp":1714160664045,"user_tz":240,"elapsed":1017,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7bad8f18-9fe0-4ed8-bfdb-6cb61e0e459c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m20240425_214007_logs\u001b[0m/  \u001b[01;34m20240425_222653_logs\u001b[0m/\n"]}]},{"cell_type":"code","source":["BASE_LOGS_PATH = 'drive/MyDrive/DS5220: Final Project/logs/densenet'"],"metadata":{"id":"IqS5m42ELcyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://pytorch.org/docs/stable/notes/mps.html\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# enable memory history, which will\n","# add tracebacks and event history to snapshots\n","#torch.cuda.memory._record_memory_history()\n","\n","# add to end of training\n","#torch.cuda.memory._dump_snapshot(\"my_snapshot.pickle\")\n"],"metadata":{"id":"Myuv5hkQXY95","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714160676281,"user_tz":240,"elapsed":2,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"outputId":"6b27ebd0-83c0-43a9-bf2a-e8a16a6609c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","source":["###################################################\n","CIFAR100_ROOT_PATH='drive/MyDrive/DS5220: Final Project'  # Modify this line with the path to the folder where folder \"cifar-10-batches-py\" locate\n","###################################################\n","\n","class Cifar100():\n","    def __init__(self,\n","                 calculate_mean_and_std = False):\n","\n","\n","\n","        if calculate_mean_and_std:\n","            self.mean, self.std = self.calculate_mean_and_std()\n","        else:\n","            self.mean, self.std = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n","\n","        self.BATCH_SIZE = 128\n","        self.transform = transforms.Compose(\n","            [transforms.ToTensor(),\n","            transforms.Normalize(self.mean, self.std)])\n","\n","        self.train_dataset = CIFAR100(root=CIFAR100_ROOT_PATH,\n","                                download=True,\n","                                train=True,\n","                                transform=self.transform)\n","\n","        self.eval_dataset = CIFAR100(root=CIFAR100_ROOT_PATH,\n","                                train=False,\n","                                transform=self.transform)\n","\n","        self.train_data_loader = DataLoader(dataset=self.train_dataset,\n","                               num_workers=0,\n","                               batch_size=self.BATCH_SIZE,\n","                               shuffle=True)\n","\n","        self.eval_data_loader = DataLoader(dataset=self.eval_dataset,\n","                              num_workers=0,\n","                              batch_size=self.BATCH_SIZE,\n","                              shuffle=False)\n","\n","    def calculate_mean_and_std(self):\n","\n","        train_dataset = CIFAR100(root=CIFAR100_ROOT_PATH,\n","                                download=True,\n","                                train=True)\n","        # stick all the images together to form a 1600000 X 32 X 3 array\n","        x = np.concatenate([np.asarray(train_dataset[i][0]) for i in range(len(train_dataset))])\n","        # calculate the mean and std along the (0, 1) axes\n","        _mean = np.mean(x, axis=(0, 1))/255\n","        _std = np.std(x, axis=(0, 1))/255\n","        _mean = _mean.tolist()\n","        _std = _std.tolist()\n","\n","        return _mean, _std\n","\n","\n","\n","\n","class Cifar100WithAugmentation():\n","    def __init__(self, calculate_mean_and_std=False):\n","        CIFAR100_ROOT_PATH = 'drive/MyDrive/DS5220: Final Project'  # Modify this path accordingly\n","\n","        if calculate_mean_and_std:\n","            self.mean, self.std = self.calculate_mean_and_std()\n","        else:\n","            self.mean, self.std = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n","\n","        self.BATCH_SIZE = 128\n","        # data augmentation and normalization for training\n","        self.train_transform = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),  # pad 4 pixels on each side and randomly crop a 32x32 image\n","            transforms.RandomHorizontalFlip(),     # randomly flip the image horizontally\n","            transforms.ToTensor(),\n","            transforms.Normalize(self.mean, self.std)\n","        ])\n","\n","        # rormalization for evaluation (without augmentation)\n","        self.eval_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(self.mean, self.std)\n","        ])\n","\n","        self.train_dataset = CIFAR100(root=CIFAR100_ROOT_PATH,\n","                                               download=True,\n","                                               train=True,\n","                                               transform=self.train_transform)\n","\n","        self.eval_dataset = CIFAR100(root=CIFAR100_ROOT_PATH,\n","                                              train=False,\n","                                              transform=self.eval_transform)\n","\n","        self.train_data_loader = DataLoader(dataset=self.train_dataset,\n","                                            num_workers=4,\n","                                            batch_size=self.BATCH_SIZE,\n","                                            shuffle=True)\n","\n","        self.eval_data_loader = DataLoader(dataset=self.eval_dataset,\n","                                           num_workers=4,\n","                                           batch_size=self.BATCH_SIZE,\n","                                           shuffle=False)\n","\n","    def calculate_mean_and_std(self):\n","\n","        train_dataset = CIFAR100(root='drive/MyDrive/DS5220: Final Project',\n","                                          download=True,\n","                                          train=True)\n","        # concat all the images to compute the mean and std\n","        x = np.concatenate([np.asarray(train_dataset[i][0]) for i in range(len(train_dataset))])\n","        # compute mean and std along the (0, 1) axes\n","        mean = np.mean(x, axis=(0, 1)) / 255\n","        std = np.std(x, axis=(0, 1)) / 255\n","        return mean.tolist(), std.tolist()\n","\n","\n","cf100 = Cifar100(calculate_mean_and_std=True)\n","cf100_w_aug = Cifar100WithAugmentation(calculate_mean_and_std=True)\n"],"metadata":{"id":"NMfpZzhSXcsT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714160723543,"user_tz":240,"elapsed":40741,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"outputId":"5673a2cb-d202-4c63-f34c-0816a483d4f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NKGghcQZEYwv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\n","    'dataloader' : cf100_w_aug,\n","    'model': models.densenet161(),\n","    'epochs': 40,\n","    'optimizer': 'SGD',\n","    'learning_rate': 0.01,\n","    'momentum': 0.9,\n","    'weight_decay': 5e-4,\n","    'loss': nn.CrossEntropyLoss(),\n","    'log_dir': os.path.join(BASE_LOGS_PATH, time.strftime('%Y%m%d_%H%M%S') + '_logs'),\n","    'device' : device,\n","    'run_time' : None\n","}\n","\n","model = config['model']\n","model.to(device)\n","EPOCHS = config['epochs']\n","criterion = config['loss']\n","optimizer = torch.optim.SGD(model.parameters(),\n","                            lr=config['learning_rate'],\n","                            momentum=config['momentum'],\n","                            weight_decay=config['weight_decay'])\n","\n","# create log directory\n","if not os.path.exists(config['log_dir']):\n","    os.makedirs(config['log_dir'])\n","    print(f\"Directory '{config['log_dir']}' created\")\n","else:\n","    print(f\"Directory '{config['log_dir']}' already exists\")\n","\n","\n","\n","metrics_path = os.path.join(config['log_dir'], 'training_metrics.csv')\n","with open(metrics_path, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    # write the header row\n","    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Eval Loss', 'Eval Accuracy', 'Top-1 Accuracy', 'Top-5 Accuracy', 'Epoch Time (seconds)'])\n","    training_start_time = timeit.default_timer()\n","    for epoch in range(config['epochs']):\n","        start_time = timeit.default_timer()\n","        train_losses = []\n","        train_accuracies = []\n","\n","        model.train()\n","        for images, labels in config['dataloader'].train_data_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","            _, predicted = torch.max(outputs, 1)\n","            accuracy = (predicted == labels).float().mean().item()\n","            train_accuracies.append(accuracy)\n","\n","        eval_losses = []\n","        eval_accuracies = []\n","        top1_accuracies = []\n","        top5_accuracies = []\n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in config['dataloader'].eval_data_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                eval_losses.append(loss.item())\n","\n","                # calculate top-1 accuracy\n","                _, predicted = torch.max(outputs, 1)\n","                top1_accuracy = (predicted == labels).float().mean().item()\n","                top1_accuracies.append(top1_accuracy)\n","\n","                # calculate top-5 accuracy\n","                _, top5_preds = outputs.topk(5, dim=1)\n","                top5_correct = top5_preds.eq(labels.view(-1, 1).expand_as(top5_preds))\n","                top5_accuracy = top5_correct.float().sum(1).ge(1).float().mean().item()\n","                top5_accuracies.append(top5_accuracy)\n","\n","                eval_accuracies.append(top1_accuracy)\n","        # write model training info to csv\n","        end_time = timeit.default_timer()  # end timing the epoch\n","        epoch_duration = end_time - start_time\n","        writer.writerow([\n","            epoch + 1,\n","            np.mean(train_losses),\n","            np.mean(train_accuracies) * 100,\n","            np.mean(eval_losses),\n","            np.mean(eval_accuracies) * 100,\n","            np.mean(top1_accuracies) * 100,\n","            np.mean(top5_accuracies) * 100,\n","            epoch_duration\n","        ])\n","        print(f\"Epoch {epoch+1}/{config['epochs']}\")\n","        print(f\"Train Loss: {np.mean(train_losses):.4f}, Train Accuracy: {np.mean(train_accuracies) * 100:.2f}%\")\n","        print(f\"Eval Loss: {np.mean(eval_losses):.4f}, Eval Accuracy: {np.mean(eval_accuracies) * 100:.2f}%, Top-1 Accuracy: {np.mean(top1_accuracies) * 100:.2f}%, Top-5 Accuracy: {np.mean(top5_accuracies) * 100:.2f}%\")\n","    training_end_time = timeit.default_timer()  # end timing the epoch\n","    training_duration = training_end_time - training_start_time\n","    config['run_time'] = training_duration\n","\n","config_path = os.path.join(config['log_dir'], 'config.txt')\n","# output config file to directory\n","with open(config_path, 'w') as f:\n","    for key, value in config.items():\n","        f.write(f'{key}: {value}\\n')\n","\n","\n","\n","torch.save(model.state_dict(), os.path.join(config['log_dir'], 'model_state_dict.pth'))\n","torch.save(model, os.path.join(config['log_dir'], 'complete_model.pth'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9I1t9qqJrCp","executionInfo":{"status":"ok","timestamp":1714084013183,"user_tz":240,"elapsed":2806679,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"outputId":"e011bb1d-e982-4e82-9bd0-ff19bad89f63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory 'drive/MyDrive/DS5220: Final Project/logs/densenet/20240425_214007_logs' created\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","Train Loss: 3.9412, Train Accuracy: 11.38%\n","Eval Loss: 3.4527, Eval Accuracy: 18.37%, Top-1 Accuracy: 18.37%, Top-5 Accuracy: 44.80%\n","Epoch 2/40\n","Train Loss: 3.2386, Train Accuracy: 21.20%\n","Eval Loss: 3.0688, Eval Accuracy: 24.39%, Top-1 Accuracy: 24.39%, Top-5 Accuracy: 54.61%\n","Epoch 3/40\n","Train Loss: 2.8771, Train Accuracy: 27.61%\n","Eval Loss: 2.7533, Eval Accuracy: 30.56%, Top-1 Accuracy: 30.56%, Top-5 Accuracy: 61.42%\n","Epoch 4/40\n","Train Loss: 2.6211, Train Accuracy: 32.52%\n","Eval Loss: 2.5471, Eval Accuracy: 35.75%, Top-1 Accuracy: 35.75%, Top-5 Accuracy: 66.61%\n","Epoch 5/40\n","Train Loss: 2.4038, Train Accuracy: 36.75%\n","Eval Loss: 2.4662, Eval Accuracy: 36.13%, Top-1 Accuracy: 36.13%, Top-5 Accuracy: 69.18%\n","Epoch 6/40\n","Train Loss: 2.2349, Train Accuracy: 40.46%\n","Eval Loss: 2.3619, Eval Accuracy: 39.30%, Top-1 Accuracy: 39.30%, Top-5 Accuracy: 70.55%\n","Epoch 7/40\n","Train Loss: 2.0849, Train Accuracy: 44.16%\n","Eval Loss: 2.2720, Eval Accuracy: 41.21%, Top-1 Accuracy: 41.21%, Top-5 Accuracy: 72.50%\n","Epoch 8/40\n","Train Loss: 1.9447, Train Accuracy: 47.18%\n","Eval Loss: 2.1867, Eval Accuracy: 43.26%, Top-1 Accuracy: 43.26%, Top-5 Accuracy: 73.48%\n","Epoch 9/40\n","Train Loss: 1.8215, Train Accuracy: 49.76%\n","Eval Loss: 2.0712, Eval Accuracy: 46.38%, Top-1 Accuracy: 46.38%, Top-5 Accuracy: 75.59%\n","Epoch 10/40\n","Train Loss: 1.7134, Train Accuracy: 52.34%\n","Eval Loss: 2.0595, Eval Accuracy: 46.26%, Top-1 Accuracy: 46.26%, Top-5 Accuracy: 76.82%\n","Epoch 11/40\n","Train Loss: 1.6160, Train Accuracy: 54.63%\n","Eval Loss: 1.9958, Eval Accuracy: 47.42%, Top-1 Accuracy: 47.42%, Top-5 Accuracy: 77.66%\n","Epoch 12/40\n","Train Loss: 1.5173, Train Accuracy: 57.14%\n","Eval Loss: 1.9657, Eval Accuracy: 48.08%, Top-1 Accuracy: 48.08%, Top-5 Accuracy: 78.26%\n","Epoch 13/40\n","Train Loss: 1.4234, Train Accuracy: 59.58%\n","Eval Loss: 1.9359, Eval Accuracy: 49.86%, Top-1 Accuracy: 49.86%, Top-5 Accuracy: 79.11%\n","Epoch 14/40\n","Train Loss: 1.3373, Train Accuracy: 61.80%\n","Eval Loss: 1.9747, Eval Accuracy: 48.79%, Top-1 Accuracy: 48.79%, Top-5 Accuracy: 78.02%\n","Epoch 15/40\n","Train Loss: 1.2559, Train Accuracy: 63.33%\n","Eval Loss: 1.9176, Eval Accuracy: 50.89%, Top-1 Accuracy: 50.89%, Top-5 Accuracy: 79.10%\n","Epoch 16/40\n","Train Loss: 1.1752, Train Accuracy: 65.75%\n","Eval Loss: 1.9326, Eval Accuracy: 50.70%, Top-1 Accuracy: 50.70%, Top-5 Accuracy: 79.12%\n","Epoch 17/40\n","Train Loss: 1.0994, Train Accuracy: 67.71%\n","Eval Loss: 1.9431, Eval Accuracy: 51.14%, Top-1 Accuracy: 51.14%, Top-5 Accuracy: 79.52%\n","Epoch 18/40\n","Train Loss: 1.0416, Train Accuracy: 68.99%\n","Eval Loss: 1.8940, Eval Accuracy: 52.20%, Top-1 Accuracy: 52.20%, Top-5 Accuracy: 80.30%\n","Epoch 19/40\n","Train Loss: 0.9753, Train Accuracy: 70.93%\n","Eval Loss: 1.9069, Eval Accuracy: 52.33%, Top-1 Accuracy: 52.33%, Top-5 Accuracy: 80.03%\n","Epoch 20/40\n","Train Loss: 0.9039, Train Accuracy: 73.01%\n","Eval Loss: 1.9347, Eval Accuracy: 51.64%, Top-1 Accuracy: 51.64%, Top-5 Accuracy: 79.75%\n","Epoch 21/40\n","Train Loss: 0.8542, Train Accuracy: 74.43%\n","Eval Loss: 1.9333, Eval Accuracy: 52.15%, Top-1 Accuracy: 52.15%, Top-5 Accuracy: 79.67%\n","Epoch 22/40\n","Train Loss: 0.8016, Train Accuracy: 75.64%\n","Eval Loss: 1.9668, Eval Accuracy: 51.97%, Top-1 Accuracy: 51.97%, Top-5 Accuracy: 79.53%\n","Epoch 23/40\n","Train Loss: 0.7325, Train Accuracy: 77.79%\n","Eval Loss: 1.9501, Eval Accuracy: 52.45%, Top-1 Accuracy: 52.45%, Top-5 Accuracy: 81.08%\n","Epoch 24/40\n","Train Loss: 0.6805, Train Accuracy: 79.11%\n","Eval Loss: 1.9713, Eval Accuracy: 52.57%, Top-1 Accuracy: 52.57%, Top-5 Accuracy: 80.24%\n","Epoch 25/40\n","Train Loss: 0.6410, Train Accuracy: 80.24%\n","Eval Loss: 1.9813, Eval Accuracy: 53.14%, Top-1 Accuracy: 53.14%, Top-5 Accuracy: 80.12%\n","Epoch 26/40\n","Train Loss: 0.6056, Train Accuracy: 81.51%\n","Eval Loss: 2.0217, Eval Accuracy: 52.09%, Top-1 Accuracy: 52.09%, Top-5 Accuracy: 80.17%\n","Epoch 27/40\n","Train Loss: 0.5661, Train Accuracy: 82.41%\n","Eval Loss: 2.0258, Eval Accuracy: 53.18%, Top-1 Accuracy: 53.18%, Top-5 Accuracy: 80.04%\n","Epoch 28/40\n","Train Loss: 0.5223, Train Accuracy: 83.97%\n","Eval Loss: 2.0388, Eval Accuracy: 52.97%, Top-1 Accuracy: 52.97%, Top-5 Accuracy: 80.35%\n","Epoch 29/40\n","Train Loss: 0.4882, Train Accuracy: 85.04%\n","Eval Loss: 1.9644, Eval Accuracy: 53.81%, Top-1 Accuracy: 53.81%, Top-5 Accuracy: 80.87%\n","Epoch 30/40\n","Train Loss: 0.4498, Train Accuracy: 86.26%\n","Eval Loss: 2.0368, Eval Accuracy: 53.85%, Top-1 Accuracy: 53.85%, Top-5 Accuracy: 80.39%\n","Epoch 31/40\n","Train Loss: 0.4324, Train Accuracy: 86.65%\n","Eval Loss: 2.0857, Eval Accuracy: 52.67%, Top-1 Accuracy: 52.67%, Top-5 Accuracy: 80.31%\n","Epoch 32/40\n","Train Loss: 0.4087, Train Accuracy: 87.56%\n","Eval Loss: 2.0923, Eval Accuracy: 53.08%, Top-1 Accuracy: 53.08%, Top-5 Accuracy: 79.97%\n","Epoch 33/40\n","Train Loss: 0.3790, Train Accuracy: 88.54%\n","Eval Loss: 2.0611, Eval Accuracy: 53.80%, Top-1 Accuracy: 53.80%, Top-5 Accuracy: 80.78%\n","Epoch 34/40\n","Train Loss: 0.3681, Train Accuracy: 88.74%\n","Eval Loss: 2.0894, Eval Accuracy: 53.52%, Top-1 Accuracy: 53.52%, Top-5 Accuracy: 80.04%\n","Epoch 35/40\n","Train Loss: 0.3382, Train Accuracy: 89.92%\n","Eval Loss: 2.0789, Eval Accuracy: 53.90%, Top-1 Accuracy: 53.90%, Top-5 Accuracy: 80.67%\n","Epoch 36/40\n","Train Loss: 0.3357, Train Accuracy: 89.69%\n","Eval Loss: 2.1632, Eval Accuracy: 52.46%, Top-1 Accuracy: 52.46%, Top-5 Accuracy: 79.50%\n","Epoch 37/40\n","Train Loss: 0.3094, Train Accuracy: 90.64%\n","Eval Loss: 2.1029, Eval Accuracy: 53.44%, Top-1 Accuracy: 53.44%, Top-5 Accuracy: 80.18%\n","Epoch 38/40\n","Train Loss: 0.2945, Train Accuracy: 91.12%\n","Eval Loss: 2.0493, Eval Accuracy: 54.92%, Top-1 Accuracy: 54.92%, Top-5 Accuracy: 80.75%\n","Epoch 39/40\n","Train Loss: 0.2948, Train Accuracy: 91.12%\n","Eval Loss: 2.1121, Eval Accuracy: 53.29%, Top-1 Accuracy: 53.29%, Top-5 Accuracy: 80.31%\n","Epoch 40/40\n","Train Loss: 0.2860, Train Accuracy: 91.43%\n","Eval Loss: 2.0607, Eval Accuracy: 54.77%, Top-1 Accuracy: 54.77%, Top-5 Accuracy: 80.96%\n"]}]},{"cell_type":"code","source":["class CustomDenseNet161(nn.Module):\n","    def __init__(self, dropout_rate=0.5, num_classes=100):\n","        super(CustomDenseNet161, self).__init__()\n","        # Initialize DenseNet161 without pre-trained weights\n","        densenet = models.densenet161(pretrained=False)\n","\n","        # Replace classifier with a new classifier that includes dropout\n","        self.features = densenet.features\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(densenet.classifier.in_features, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        out = nn.functional.relu(features, inplace=True)\n","        out = nn.functional.adaptive_avg_pool2d(out, (1, 1))\n","        out = torch.flatten(out, 1)\n","        out = self.classifier(out)\n","        return out\n","\n","config = {\n","    'dataloader' : cf100_w_aug,\n","    'model': CustomDenseNet161(dropout_rate=0.5, num_classes=100),\n","    'epochs': 40,\n","    'optimizer': 'SGD',\n","    'learning_rate': 0.01,\n","    'momentum': 0.9,\n","    'weight_decay': 5e-4,\n","    'loss': nn.CrossEntropyLoss(),\n","    'log_dir': os.path.join(BASE_LOGS_PATH, time.strftime('%Y%m%d_%H%M%S') + '_logs'),\n","    'device' : device,\n","    'run_time' : None\n","}\n","\n","model = config['model']\n","model.to(config['device'])\n","EPOCHS = config['epochs']\n","criterion = config['loss']\n","optimizer = torch.optim.SGD(model.parameters(),\n","                            lr=config['learning_rate'],\n","                            momentum=config['momentum'],\n","                            weight_decay=config['weight_decay'])\n","\n","# create log directory\n","if not os.path.exists(config['log_dir']):\n","    os.makedirs(config['log_dir'])\n","    print(f\"Directory '{config['log_dir']}' created\")\n","else:\n","    print(f\"Directory '{config['log_dir']}' already exists\")\n","\n","\n","\n","metrics_path = os.path.join(config['log_dir'], 'training_metrics.csv')\n","with open(metrics_path, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    # write the header row\n","    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Eval Loss', 'Eval Accuracy', 'Top-1 Accuracy', 'Top-5 Accuracy', 'Epoch Time (seconds)'])\n","    training_start_time = timeit.default_timer()\n","    for epoch in range(config['epochs']):\n","        start_time = timeit.default_timer()\n","        train_losses = []\n","        train_accuracies = []\n","\n","        model.train()\n","        for images, labels in config['dataloader'].train_data_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","            _, predicted = torch.max(outputs, 1)\n","            accuracy = (predicted == labels).float().mean().item()\n","            train_accuracies.append(accuracy)\n","\n","        eval_losses = []\n","        eval_accuracies = []\n","        top1_accuracies = []\n","        top5_accuracies = []\n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in config['dataloader'].eval_data_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                eval_losses.append(loss.item())\n","\n","                # calculate top-1 accuracy\n","                _, predicted = torch.max(outputs, 1)\n","                top1_accuracy = (predicted == labels).float().mean().item()\n","                top1_accuracies.append(top1_accuracy)\n","\n","                # calculate top-5 accuracy\n","                _, top5_preds = outputs.topk(5, dim=1)\n","                top5_correct = top5_preds.eq(labels.view(-1, 1).expand_as(top5_preds))\n","                top5_accuracy = top5_correct.float().sum(1).ge(1).float().mean().item()\n","                top5_accuracies.append(top5_accuracy)\n","\n","                eval_accuracies.append(top1_accuracy)\n","        # write model training info to csv\n","        end_time = timeit.default_timer()  # end timing the epoch\n","        epoch_duration = end_time - start_time\n","        writer.writerow([\n","            epoch + 1,\n","            np.mean(train_losses),\n","            np.mean(train_accuracies) * 100,\n","            np.mean(eval_losses),\n","            np.mean(eval_accuracies) * 100,\n","            np.mean(top1_accuracies) * 100,\n","            np.mean(top5_accuracies) * 100,\n","            epoch_duration\n","        ])\n","        print(f\"Epoch {epoch+1}/{config['epochs']}\")\n","        print(f\"Train Loss: {np.mean(train_losses):.4f}, Train Accuracy: {np.mean(train_accuracies) * 100:.2f}%\")\n","        print(f\"Eval Loss: {np.mean(eval_losses):.4f}, Eval Accuracy: {np.mean(eval_accuracies) * 100:.2f}%, Top-1 Accuracy: {np.mean(top1_accuracies) * 100:.2f}%, Top-5 Accuracy: {np.mean(top5_accuracies) * 100:.2f}%\")\n","    training_end_time = timeit.default_timer()  # end timing the epoch\n","    training_duration = training_end_time - training_start_time\n","    config['run_time'] = training_duration\n","\n","config_path = os.path.join(config['log_dir'], 'config.txt')\n","# output config file to directory\n","with open(config_path, 'w') as f:\n","    for key, value in config.items():\n","        f.write(f'{key}: {value}\\n')\n","\n","\n","\n","torch.save(model.state_dict(), os.path.join(config['log_dir'], 'model_state_dict.pth'))\n","torch.save(model, os.path.join(config['log_dir'], 'complete_model.pth'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JW2iheln7WDC","executionInfo":{"status":"ok","timestamp":1714163717556,"user_tz":240,"elapsed":2798881,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"outputId":"4a112277-36a8-4d2c-f09f-7e153e8b7d5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory 'drive/MyDrive/DS5220: Final Project/logs/densenet/20240426_194838_logs' created\n","Epoch 1/40\n","Train Loss: 4.1093, Train Accuracy: 8.73%\n","Eval Loss: 3.6482, Eval Accuracy: 14.87%, Top-1 Accuracy: 14.87%, Top-5 Accuracy: 39.81%\n","Epoch 2/40\n","Train Loss: 3.5408, Train Accuracy: 16.47%\n","Eval Loss: 3.2464, Eval Accuracy: 22.24%, Top-1 Accuracy: 22.24%, Top-5 Accuracy: 50.48%\n","Epoch 3/40\n","Train Loss: 3.1920, Train Accuracy: 22.40%\n","Eval Loss: 3.0125, Eval Accuracy: 26.62%, Top-1 Accuracy: 26.62%, Top-5 Accuracy: 57.02%\n","Epoch 4/40\n","Train Loss: 2.9266, Train Accuracy: 27.04%\n","Eval Loss: 2.7743, Eval Accuracy: 30.60%, Top-1 Accuracy: 30.60%, Top-5 Accuracy: 61.76%\n","Epoch 5/40\n","Train Loss: 2.7172, Train Accuracy: 30.82%\n","Eval Loss: 2.5427, Eval Accuracy: 34.56%, Top-1 Accuracy: 34.56%, Top-5 Accuracy: 66.71%\n","Epoch 6/40\n","Train Loss: 2.5413, Train Accuracy: 34.32%\n","Eval Loss: 2.4323, Eval Accuracy: 37.45%, Top-1 Accuracy: 37.45%, Top-5 Accuracy: 69.21%\n","Epoch 7/40\n","Train Loss: 2.4012, Train Accuracy: 37.30%\n","Eval Loss: 2.3506, Eval Accuracy: 39.17%, Top-1 Accuracy: 39.17%, Top-5 Accuracy: 70.73%\n","Epoch 8/40\n","Train Loss: 2.2656, Train Accuracy: 40.02%\n","Eval Loss: 2.2078, Eval Accuracy: 41.80%, Top-1 Accuracy: 41.80%, Top-5 Accuracy: 73.28%\n","Epoch 9/40\n","Train Loss: 2.1493, Train Accuracy: 42.56%\n","Eval Loss: 2.1630, Eval Accuracy: 42.38%, Top-1 Accuracy: 42.38%, Top-5 Accuracy: 74.37%\n","Epoch 10/40\n","Train Loss: 2.0407, Train Accuracy: 44.73%\n","Eval Loss: 2.0772, Eval Accuracy: 45.15%, Top-1 Accuracy: 45.15%, Top-5 Accuracy: 75.99%\n","Epoch 11/40\n","Train Loss: 1.9412, Train Accuracy: 47.14%\n","Eval Loss: 2.0119, Eval Accuracy: 47.33%, Top-1 Accuracy: 47.33%, Top-5 Accuracy: 76.84%\n","Epoch 12/40\n","Train Loss: 1.8406, Train Accuracy: 49.36%\n","Eval Loss: 1.9389, Eval Accuracy: 48.33%, Top-1 Accuracy: 48.33%, Top-5 Accuracy: 78.23%\n","Epoch 13/40\n","Train Loss: 1.7650, Train Accuracy: 51.13%\n","Eval Loss: 1.9927, Eval Accuracy: 47.65%, Top-1 Accuracy: 47.65%, Top-5 Accuracy: 77.78%\n","Epoch 14/40\n","Train Loss: 1.6744, Train Accuracy: 53.16%\n","Eval Loss: 1.9131, Eval Accuracy: 49.51%, Top-1 Accuracy: 49.51%, Top-5 Accuracy: 78.74%\n","Epoch 15/40\n","Train Loss: 1.6147, Train Accuracy: 54.56%\n","Eval Loss: 1.8766, Eval Accuracy: 50.48%, Top-1 Accuracy: 50.48%, Top-5 Accuracy: 79.44%\n","Epoch 16/40\n","Train Loss: 1.5357, Train Accuracy: 56.61%\n","Eval Loss: 1.8529, Eval Accuracy: 50.62%, Top-1 Accuracy: 50.62%, Top-5 Accuracy: 79.60%\n","Epoch 17/40\n","Train Loss: 1.4665, Train Accuracy: 58.27%\n","Eval Loss: 1.8905, Eval Accuracy: 50.40%, Top-1 Accuracy: 50.40%, Top-5 Accuracy: 79.85%\n","Epoch 18/40\n","Train Loss: 1.4047, Train Accuracy: 59.84%\n","Eval Loss: 1.7961, Eval Accuracy: 52.25%, Top-1 Accuracy: 52.25%, Top-5 Accuracy: 80.98%\n","Epoch 19/40\n","Train Loss: 1.3432, Train Accuracy: 61.39%\n","Eval Loss: 1.8103, Eval Accuracy: 52.23%, Top-1 Accuracy: 52.23%, Top-5 Accuracy: 80.96%\n","Epoch 20/40\n","Train Loss: 1.2903, Train Accuracy: 62.82%\n","Eval Loss: 1.8023, Eval Accuracy: 53.48%, Top-1 Accuracy: 53.48%, Top-5 Accuracy: 81.03%\n","Epoch 21/40\n","Train Loss: 1.2226, Train Accuracy: 64.55%\n","Eval Loss: 1.8301, Eval Accuracy: 52.24%, Top-1 Accuracy: 52.24%, Top-5 Accuracy: 80.82%\n","Epoch 22/40\n","Train Loss: 1.1795, Train Accuracy: 65.65%\n","Eval Loss: 1.7902, Eval Accuracy: 53.32%, Top-1 Accuracy: 53.32%, Top-5 Accuracy: 81.83%\n","Epoch 23/40\n","Train Loss: 1.1359, Train Accuracy: 66.69%\n","Eval Loss: 1.7940, Eval Accuracy: 53.24%, Top-1 Accuracy: 53.24%, Top-5 Accuracy: 81.49%\n","Epoch 24/40\n","Train Loss: 1.0927, Train Accuracy: 67.85%\n","Eval Loss: 1.7670, Eval Accuracy: 54.03%, Top-1 Accuracy: 54.03%, Top-5 Accuracy: 81.81%\n","Epoch 25/40\n","Train Loss: 1.0384, Train Accuracy: 69.34%\n","Eval Loss: 1.7549, Eval Accuracy: 55.44%, Top-1 Accuracy: 55.44%, Top-5 Accuracy: 82.39%\n","Epoch 26/40\n","Train Loss: 0.9995, Train Accuracy: 70.28%\n","Eval Loss: 1.7834, Eval Accuracy: 54.19%, Top-1 Accuracy: 54.19%, Top-5 Accuracy: 82.13%\n","Epoch 27/40\n","Train Loss: 0.9547, Train Accuracy: 71.33%\n","Eval Loss: 1.7618, Eval Accuracy: 55.39%, Top-1 Accuracy: 55.39%, Top-5 Accuracy: 82.57%\n","Epoch 28/40\n","Train Loss: 0.9070, Train Accuracy: 72.95%\n","Eval Loss: 1.7484, Eval Accuracy: 55.55%, Top-1 Accuracy: 55.55%, Top-5 Accuracy: 82.73%\n","Epoch 29/40\n","Train Loss: 0.8737, Train Accuracy: 73.77%\n","Eval Loss: 1.7476, Eval Accuracy: 55.48%, Top-1 Accuracy: 55.48%, Top-5 Accuracy: 82.66%\n","Epoch 30/40\n","Train Loss: 0.8466, Train Accuracy: 74.49%\n","Eval Loss: 1.7731, Eval Accuracy: 55.79%, Top-1 Accuracy: 55.79%, Top-5 Accuracy: 82.45%\n","Epoch 31/40\n","Train Loss: 0.8003, Train Accuracy: 75.77%\n","Eval Loss: 1.8099, Eval Accuracy: 55.18%, Top-1 Accuracy: 55.18%, Top-5 Accuracy: 82.33%\n","Epoch 32/40\n","Train Loss: 0.7733, Train Accuracy: 76.45%\n","Eval Loss: 1.7951, Eval Accuracy: 55.73%, Top-1 Accuracy: 55.73%, Top-5 Accuracy: 82.44%\n","Epoch 33/40\n","Train Loss: 0.7359, Train Accuracy: 77.43%\n","Eval Loss: 1.7948, Eval Accuracy: 56.17%, Top-1 Accuracy: 56.17%, Top-5 Accuracy: 82.38%\n","Epoch 34/40\n","Train Loss: 0.7020, Train Accuracy: 78.60%\n","Eval Loss: 1.8124, Eval Accuracy: 55.84%, Top-1 Accuracy: 55.84%, Top-5 Accuracy: 82.62%\n","Epoch 35/40\n","Train Loss: 0.6680, Train Accuracy: 79.74%\n","Eval Loss: 1.8362, Eval Accuracy: 55.59%, Top-1 Accuracy: 55.59%, Top-5 Accuracy: 82.39%\n","Epoch 36/40\n","Train Loss: 0.6466, Train Accuracy: 80.35%\n","Eval Loss: 1.8825, Eval Accuracy: 55.44%, Top-1 Accuracy: 55.44%, Top-5 Accuracy: 81.81%\n","Epoch 37/40\n","Train Loss: 0.6196, Train Accuracy: 80.97%\n","Eval Loss: 1.8333, Eval Accuracy: 55.82%, Top-1 Accuracy: 55.82%, Top-5 Accuracy: 82.80%\n","Epoch 38/40\n","Train Loss: 0.6008, Train Accuracy: 81.63%\n","Eval Loss: 1.8367, Eval Accuracy: 55.74%, Top-1 Accuracy: 55.74%, Top-5 Accuracy: 82.83%\n","Epoch 39/40\n","Train Loss: 0.5607, Train Accuracy: 82.75%\n","Eval Loss: 1.9208, Eval Accuracy: 54.97%, Top-1 Accuracy: 54.97%, Top-5 Accuracy: 81.92%\n","Epoch 40/40\n","Train Loss: 0.5399, Train Accuracy: 83.45%\n","Eval Loss: 1.8951, Eval Accuracy: 55.56%, Top-1 Accuracy: 55.56%, Top-5 Accuracy: 82.22%\n"]}]},{"cell_type":"code","source":["config = {\n","    'dataloader' : cf100_w_aug,\n","    'model': models.densenet121(),\n","    'epochs': 40,\n","    'optimizer': 'SGD',\n","    'learning_rate': 0.01,\n","    'momentum': 0.9,\n","    'weight_decay': 5e-4,\n","    'loss': nn.CrossEntropyLoss(),\n","    'log_dir': os.path.join(BASE_LOGS_PATH, time.strftime('%Y%m%d_%H%M%S') + '_logs'),\n","    'device' : device,\n","    'run_time' : None\n","}\n","\n","model = config['model']\n","model.to(device)\n","EPOCHS = config['epochs']\n","criterion = config['loss']\n","optimizer = torch.optim.SGD(model.parameters(),\n","                            lr=config['learning_rate'],\n","                            momentum=config['momentum'],\n","                            weight_decay=config['weight_decay'])\n","\n","# create log directory\n","if not os.path.exists(config['log_dir']):\n","    os.makedirs(config['log_dir'])\n","    print(f\"Directory '{config['log_dir']}' created\")\n","else:\n","    print(f\"Directory '{config['log_dir']}' already exists\")\n","\n","\n","\n","metrics_path = os.path.join(config['log_dir'], 'training_metrics.csv')\n","with open(metrics_path, mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    # write the header row\n","    writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy', 'Eval Loss', 'Eval Accuracy', 'Top-1 Accuracy', 'Top-5 Accuracy', 'Epoch Time (seconds)'])\n","    training_start_time = timeit.default_timer()\n","    for epoch in range(config['epochs']):\n","        start_time = timeit.default_timer()\n","        train_losses = []\n","        train_accuracies = []\n","\n","        model.train()\n","        for images, labels in config['dataloader'].train_data_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","            _, predicted = torch.max(outputs, 1)\n","            accuracy = (predicted == labels).float().mean().item()\n","            train_accuracies.append(accuracy)\n","\n","        eval_losses = []\n","        eval_accuracies = []\n","        top1_accuracies = []\n","        top5_accuracies = []\n","        model.eval()\n","        with torch.no_grad():\n","            for images, labels in config['dataloader'].eval_data_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                eval_losses.append(loss.item())\n","\n","                # calculate top-1 accuracy\n","                _, predicted = torch.max(outputs, 1)\n","                top1_accuracy = (predicted == labels).float().mean().item()\n","                top1_accuracies.append(top1_accuracy)\n","\n","                # calculate top-5 accuracy\n","                _, top5_preds = outputs.topk(5, dim=1)\n","                top5_correct = top5_preds.eq(labels.view(-1, 1).expand_as(top5_preds))\n","                top5_accuracy = top5_correct.float().sum(1).ge(1).float().mean().item()\n","                top5_accuracies.append(top5_accuracy)\n","\n","                eval_accuracies.append(top1_accuracy)\n","        # write model training info to csv\n","        end_time = timeit.default_timer()  # end timing the epoch\n","        epoch_duration = end_time - start_time\n","        writer.writerow([\n","            epoch + 1,\n","            np.mean(train_losses),\n","            np.mean(train_accuracies) * 100,\n","            np.mean(eval_losses),\n","            np.mean(eval_accuracies) * 100,\n","            np.mean(top1_accuracies) * 100,\n","            np.mean(top5_accuracies) * 100,\n","            epoch_duration\n","        ])\n","        print(f\"Epoch {epoch+1}/{config['epochs']}\")\n","        print(f\"Train Loss: {np.mean(train_losses):.4f}, Train Accuracy: {np.mean(train_accuracies) * 100:.2f}%\")\n","        print(f\"Eval Loss: {np.mean(eval_losses):.4f}, Eval Accuracy: {np.mean(eval_accuracies) * 100:.2f}%, Top-1 Accuracy: {np.mean(top1_accuracies) * 100:.2f}%, Top-5 Accuracy: {np.mean(top5_accuracies) * 100:.2f}%\")\n","    training_end_time = timeit.default_timer()  # end timing the epoch\n","    training_duration = training_end_time - training_start_time\n","    config['run_time'] = training_duration\n","\n","config_path = os.path.join(config['log_dir'], 'config.txt')\n","# output config file to directory\n","with open(config_path, 'w') as f:\n","    for key, value in config.items():\n","        f.write(f'{key}: {value}\\n')\n","\n","\n","\n","torch.save(model.state_dict(), os.path.join(config['log_dir'], 'model_state_dict.pth'))\n","torch.save(model, os.path.join(config['log_dir'], 'complete_model.pth'))\n"],"metadata":{"id":"kY7_luWx2M-r","executionInfo":{"status":"ok","timestamp":1714086261547,"user_tz":240,"elapsed":2248367,"user":{"displayName":"Shane Hussey","userId":"18201295195567318576"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9dc62088-8f55-4f21-dd7f-983b45b5edb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory 'drive/MyDrive/DS5220: Final Project/logs/densenet/20240425_222653_logs' created\n","Epoch 1/40\n","Train Loss: 4.0236, Train Accuracy: 10.65%\n","Eval Loss: 3.4594, Eval Accuracy: 17.34%, Top-1 Accuracy: 17.34%, Top-5 Accuracy: 44.47%\n","Epoch 2/40\n","Train Loss: 3.2625, Train Accuracy: 20.41%\n","Eval Loss: 3.0544, Eval Accuracy: 25.04%, Top-1 Accuracy: 25.04%, Top-5 Accuracy: 53.51%\n","Epoch 3/40\n","Train Loss: 2.9417, Train Accuracy: 26.40%\n","Eval Loss: 2.8547, Eval Accuracy: 28.59%, Top-1 Accuracy: 28.59%, Top-5 Accuracy: 59.69%\n","Epoch 4/40\n","Train Loss: 2.7183, Train Accuracy: 30.60%\n","Eval Loss: 2.6921, Eval Accuracy: 31.94%, Top-1 Accuracy: 31.94%, Top-5 Accuracy: 62.95%\n","Epoch 5/40\n","Train Loss: 2.5374, Train Accuracy: 34.32%\n","Eval Loss: 2.5198, Eval Accuracy: 34.83%, Top-1 Accuracy: 34.83%, Top-5 Accuracy: 66.84%\n","Epoch 6/40\n","Train Loss: 2.3929, Train Accuracy: 37.21%\n","Eval Loss: 2.4004, Eval Accuracy: 37.74%, Top-1 Accuracy: 37.74%, Top-5 Accuracy: 69.00%\n","Epoch 7/40\n","Train Loss: 2.2565, Train Accuracy: 39.99%\n","Eval Loss: 2.3148, Eval Accuracy: 39.82%, Top-1 Accuracy: 39.82%, Top-5 Accuracy: 71.02%\n","Epoch 8/40\n","Train Loss: 2.1437, Train Accuracy: 42.73%\n","Eval Loss: 2.2904, Eval Accuracy: 40.35%, Top-1 Accuracy: 40.35%, Top-5 Accuracy: 71.46%\n","Epoch 9/40\n","Train Loss: 2.0454, Train Accuracy: 44.74%\n","Eval Loss: 2.1882, Eval Accuracy: 42.98%, Top-1 Accuracy: 42.98%, Top-5 Accuracy: 73.45%\n","Epoch 10/40\n","Train Loss: 1.9360, Train Accuracy: 47.25%\n","Eval Loss: 2.1685, Eval Accuracy: 43.67%, Top-1 Accuracy: 43.67%, Top-5 Accuracy: 73.86%\n","Epoch 11/40\n","Train Loss: 1.8616, Train Accuracy: 49.03%\n","Eval Loss: 2.1580, Eval Accuracy: 43.76%, Top-1 Accuracy: 43.76%, Top-5 Accuracy: 74.15%\n","Epoch 12/40\n","Train Loss: 1.7796, Train Accuracy: 50.99%\n","Eval Loss: 2.0606, Eval Accuracy: 45.92%, Top-1 Accuracy: 45.92%, Top-5 Accuracy: 76.17%\n","Epoch 13/40\n","Train Loss: 1.7042, Train Accuracy: 52.71%\n","Eval Loss: 1.9759, Eval Accuracy: 48.49%, Top-1 Accuracy: 48.49%, Top-5 Accuracy: 77.62%\n","Epoch 14/40\n","Train Loss: 1.6264, Train Accuracy: 54.80%\n","Eval Loss: 2.0203, Eval Accuracy: 47.32%, Top-1 Accuracy: 47.32%, Top-5 Accuracy: 77.02%\n","Epoch 15/40\n","Train Loss: 1.5656, Train Accuracy: 55.89%\n","Eval Loss: 1.9702, Eval Accuracy: 48.66%, Top-1 Accuracy: 48.66%, Top-5 Accuracy: 77.63%\n","Epoch 16/40\n","Train Loss: 1.5026, Train Accuracy: 57.45%\n","Eval Loss: 2.0243, Eval Accuracy: 47.72%, Top-1 Accuracy: 47.72%, Top-5 Accuracy: 77.34%\n","Epoch 17/40\n","Train Loss: 1.4423, Train Accuracy: 59.07%\n","Eval Loss: 1.9190, Eval Accuracy: 49.75%, Top-1 Accuracy: 49.75%, Top-5 Accuracy: 79.24%\n","Epoch 18/40\n","Train Loss: 1.3835, Train Accuracy: 60.42%\n","Eval Loss: 1.9296, Eval Accuracy: 49.55%, Top-1 Accuracy: 49.55%, Top-5 Accuracy: 78.91%\n","Epoch 19/40\n","Train Loss: 1.3331, Train Accuracy: 61.76%\n","Eval Loss: 1.8712, Eval Accuracy: 50.92%, Top-1 Accuracy: 50.92%, Top-5 Accuracy: 79.73%\n","Epoch 20/40\n","Train Loss: 1.2781, Train Accuracy: 63.30%\n","Eval Loss: 1.9084, Eval Accuracy: 50.14%, Top-1 Accuracy: 50.14%, Top-5 Accuracy: 79.62%\n","Epoch 21/40\n","Train Loss: 1.2357, Train Accuracy: 64.06%\n","Eval Loss: 1.9065, Eval Accuracy: 50.98%, Top-1 Accuracy: 50.98%, Top-5 Accuracy: 79.43%\n","Epoch 22/40\n","Train Loss: 1.1946, Train Accuracy: 65.11%\n","Eval Loss: 1.8748, Eval Accuracy: 51.20%, Top-1 Accuracy: 51.20%, Top-5 Accuracy: 80.10%\n","Epoch 23/40\n","Train Loss: 1.1347, Train Accuracy: 66.65%\n","Eval Loss: 1.8956, Eval Accuracy: 51.36%, Top-1 Accuracy: 51.36%, Top-5 Accuracy: 80.04%\n","Epoch 24/40\n","Train Loss: 1.1031, Train Accuracy: 67.78%\n","Eval Loss: 1.9295, Eval Accuracy: 50.91%, Top-1 Accuracy: 50.91%, Top-5 Accuracy: 79.53%\n","Epoch 25/40\n","Train Loss: 1.0535, Train Accuracy: 69.08%\n","Eval Loss: 1.9020, Eval Accuracy: 51.56%, Top-1 Accuracy: 51.56%, Top-5 Accuracy: 79.98%\n","Epoch 26/40\n","Train Loss: 1.0203, Train Accuracy: 69.86%\n","Eval Loss: 1.9150, Eval Accuracy: 51.20%, Top-1 Accuracy: 51.20%, Top-5 Accuracy: 79.91%\n","Epoch 27/40\n","Train Loss: 0.9712, Train Accuracy: 71.27%\n","Eval Loss: 1.8993, Eval Accuracy: 51.75%, Top-1 Accuracy: 51.75%, Top-5 Accuracy: 80.62%\n","Epoch 28/40\n","Train Loss: 0.9438, Train Accuracy: 71.71%\n","Eval Loss: 1.9161, Eval Accuracy: 52.06%, Top-1 Accuracy: 52.06%, Top-5 Accuracy: 80.34%\n","Epoch 29/40\n","Train Loss: 0.9068, Train Accuracy: 72.79%\n","Eval Loss: 1.9103, Eval Accuracy: 52.65%, Top-1 Accuracy: 52.65%, Top-5 Accuracy: 80.16%\n","Epoch 30/40\n","Train Loss: 0.8727, Train Accuracy: 73.45%\n","Eval Loss: 1.9044, Eval Accuracy: 52.10%, Top-1 Accuracy: 52.10%, Top-5 Accuracy: 80.61%\n","Epoch 31/40\n","Train Loss: 0.8260, Train Accuracy: 75.21%\n","Eval Loss: 1.9714, Eval Accuracy: 50.91%, Top-1 Accuracy: 50.91%, Top-5 Accuracy: 80.29%\n","Epoch 32/40\n","Train Loss: 0.8141, Train Accuracy: 75.49%\n","Eval Loss: 1.9351, Eval Accuracy: 51.81%, Top-1 Accuracy: 51.81%, Top-5 Accuracy: 80.50%\n","Epoch 33/40\n","Train Loss: 0.7748, Train Accuracy: 76.71%\n","Eval Loss: 1.9667, Eval Accuracy: 51.66%, Top-1 Accuracy: 51.66%, Top-5 Accuracy: 80.06%\n","Epoch 34/40\n","Train Loss: 0.7434, Train Accuracy: 77.34%\n","Eval Loss: 2.0169, Eval Accuracy: 51.51%, Top-1 Accuracy: 51.51%, Top-5 Accuracy: 79.69%\n","Epoch 35/40\n","Train Loss: 0.7120, Train Accuracy: 78.29%\n","Eval Loss: 2.0008, Eval Accuracy: 51.58%, Top-1 Accuracy: 51.58%, Top-5 Accuracy: 80.10%\n","Epoch 36/40\n","Train Loss: 0.6862, Train Accuracy: 78.95%\n","Eval Loss: 1.9765, Eval Accuracy: 52.68%, Top-1 Accuracy: 52.68%, Top-5 Accuracy: 80.15%\n","Epoch 37/40\n","Train Loss: 0.6526, Train Accuracy: 79.93%\n","Eval Loss: 1.9856, Eval Accuracy: 53.59%, Top-1 Accuracy: 53.59%, Top-5 Accuracy: 80.63%\n","Epoch 38/40\n","Train Loss: 0.6356, Train Accuracy: 80.39%\n","Eval Loss: 1.9413, Eval Accuracy: 54.24%, Top-1 Accuracy: 54.24%, Top-5 Accuracy: 80.90%\n","Epoch 39/40\n","Train Loss: 0.6078, Train Accuracy: 81.36%\n","Eval Loss: 1.9694, Eval Accuracy: 53.64%, Top-1 Accuracy: 53.64%, Top-5 Accuracy: 81.02%\n","Epoch 40/40\n","Train Loss: 0.6078, Train Accuracy: 81.43%\n","Eval Loss: 1.9856, Eval Accuracy: 53.67%, Top-1 Accuracy: 53.67%, Top-5 Accuracy: 80.64%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vd9BstB75UzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fmtwM4P_B1mF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"POkyrQh8FEwH"}},{"cell_type":"code","source":[],"metadata":{"id":"Nmv3_s7Db1Gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IlczGSdLcYhF"},"execution_count":null,"outputs":[]}]}